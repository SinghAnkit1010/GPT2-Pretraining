{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:15:55.071693Z",
     "iopub.status.busy": "2025-02-14T17:15:55.071385Z",
     "iopub.status.idle": "2025-02-14T17:16:10.544948Z",
     "shell.execute_reply": "2025-02-14T17:16:10.543955Z",
     "shell.execute_reply.started": "2025-02-14T17:15:55.071668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pymupdf as pmf\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gpt_download3\n",
    "from gpt_model import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:17:13.745597Z",
     "iopub.status.busy": "2025-02-14T17:17:13.745287Z",
     "iopub.status.idle": "2025-02-14T17:17:13.749379Z",
     "shell.execute_reply": "2025-02-14T17:17:13.748499Z",
     "shell.execute_reply.started": "2025-02-14T17:17:13.745575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = \"Medicina - Grays Anatomy 16th ed.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:17:14.913577Z",
     "iopub.status.busy": "2025-02-14T17:17:14.913263Z",
     "iopub.status.idle": "2025-02-14T17:17:15.228557Z",
     "shell.execute_reply": "2025-02-14T17:17:15.227914Z",
     "shell.execute_reply.started": "2025-02-14T17:17:14.913550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "doc = pmf.open(dataset_path)\n",
    "num_pages = doc.page_count\n",
    "toc = doc.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:17:17.130925Z",
     "iopub.status.busy": "2025-02-14T17:17:17.130659Z",
     "iopub.status.idle": "2025-02-14T17:17:17.139132Z",
     "shell.execute_reply": "2025-02-14T17:17:17.138228Z",
     "shell.execute_reply.started": "2025-02-14T17:17:17.130904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter: I. Embryology, Start Page: 6, End Page: 35\n",
      "Chapter: II. Osteology, Start Page: 37, End Page: 172\n",
      "Chapter: III. Syndesmology, Start Page: 174, End Page: 241\n",
      "Chapter: IV. Myology, Start Page: 243, End Page: 331\n",
      "Chapter: V. Angiology, Start Page: 333, End Page: 360\n",
      "Chapter: VI. The Arteries, Start Page: 362, End Page: 423\n",
      "Chapter: VII. The Veins, Start Page: 425, End Page: 449\n",
      "Chapter: VIII. The Lymphatic System, Start Page: 451, End Page: 471\n",
      "Chapter: IX. Neurology, Start Page: 473, End Page: 620\n",
      "Chapter: X. The Organs of the Senses and the Common Integument, Start Page: 622, End Page: 671\n",
      "Chapter: XI. Splanchnology, Start Page: 673, End Page: 814\n",
      "Chapter: XII. Surface Anatomy and Surface Markings, Start Page: 816, End Page: 852\n"
     ]
    }
   ],
   "source": [
    "page_ranges = {}\n",
    "for i in range(1,len(toc)):\n",
    "  chapter = toc[i][1]\n",
    "  start_page = toc[i][2]\n",
    "  end_page = toc[i+1][2]-2 if i < len(toc)-1 else num_pages\n",
    "  page_ranges[chapter] = (start_page,end_page)\n",
    "  print(f\"Chapter: {chapter}, Start Page: {start_page}, End Page: {end_page}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:18:32.546253Z",
     "iopub.status.busy": "2025-02-14T17:18:32.545977Z",
     "iopub.status.idle": "2025-02-14T17:18:39.493465Z",
     "shell.execute_reply": "2025-02-14T17:18:39.492755Z",
     "shell.execute_reply.started": "2025-02-14T17:18:32.546232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#extracting ninth chapter\n",
    "text = \"\"\n",
    "page_range = page_ranges['IX. Neurology']\n",
    "for i in range(page_range[0],page_range[1]):\n",
    "  page = doc.load_page(i)\n",
    "  text += page.get_text('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:18:39.494958Z",
     "iopub.status.busy": "2025-02-14T17:18:39.494671Z",
     "iopub.status.idle": "2025-02-14T17:18:39.498976Z",
     "shell.execute_reply": "2025-02-14T17:18:39.498182Z",
     "shell.execute_reply.started": "2025-02-14T17:18:39.494926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_extracted_text(text):\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace multiple newlines with space\n",
    "\n",
    "    # Fix words split across lines\n",
    "    text = re.sub(r'(\\w+)-\\s+(\\w+)', r'\\1\\2', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    # Trim spaces at the start and end\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:18:39.499821Z",
     "iopub.status.busy": "2025-02-14T17:18:39.499645Z",
     "iopub.status.idle": "2025-02-14T17:18:39.621490Z",
     "shell.execute_reply": "2025-02-14T17:18:39.620950Z",
     "shell.execute_reply.started": "2025-02-14T17:18:39.499805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cleaned_text = clean_extracted_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:18:47.494429Z",
     "iopub.status.busy": "2025-02-14T17:18:47.494098Z",
     "iopub.status.idle": "2025-02-14T17:18:47.499561Z",
     "shell.execute_reply": "2025-02-14T17:18:47.498869Z",
     "shell.execute_reply.started": "2025-02-14T17:18:47.494405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('all_chapters.txt','w') as f:\n",
    "  f.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:19:36.841975Z",
     "iopub.status.busy": "2025-02-14T17:19:36.841657Z",
     "iopub.status.idle": "2025-02-14T17:19:36.847069Z",
     "shell.execute_reply": "2025-02-14T17:19:36.846293Z",
     "shell.execute_reply.started": "2025-02-14T17:19:36.841948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "  def __init__(self,text,tokenizer,max_length,stride):\n",
    "    token_ids = tokenizer.encode(text)\n",
    "    self.input_ids = []\n",
    "    self.output_ids = []\n",
    "\n",
    "    for i in range(0,len(token_ids)-max_length,stride):\n",
    "      input_chunk = token_ids[i:i+max_length]\n",
    "      output_chunk = token_ids[i+1:i+max_length+1]\n",
    "      self.input_ids.append(torch.tensor(input_chunk))\n",
    "      self.output_ids.append(torch.tensor(output_chunk))\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "  def __getitem__(self,idx):\n",
    "    return self.input_ids[idx],self.output_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:19:44.777482Z",
     "iopub.status.busy": "2025-02-14T17:19:44.777123Z",
     "iopub.status.idle": "2025-02-14T17:19:44.782726Z",
     "shell.execute_reply": "2025-02-14T17:19:44.781949Z",
     "shell.execute_reply.started": "2025-02-14T17:19:44.777456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('all_chapters.txt','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:19:51.474483Z",
     "iopub.status.busy": "2025-02-14T17:19:51.474123Z",
     "iopub.status.idle": "2025-02-14T17:19:52.886679Z",
     "shell.execute_reply": "2025-02-14T17:19:52.885997Z",
     "shell.execute_reply.started": "2025-02-14T17:19:51.474457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:20:04.644540Z",
     "iopub.status.busy": "2025-02-14T17:20:04.644244Z",
     "iopub.status.idle": "2025-02-14T17:20:04.720432Z",
     "shell.execute_reply": "2025-02-14T17:20:04.719759Z",
     "shell.execute_reply.started": "2025-02-14T17:20:04.644518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "token_ids = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:20:23.818763Z",
     "iopub.status.busy": "2025-02-14T17:20:23.818480Z",
     "iopub.status.idle": "2025-02-14T17:20:23.824961Z",
     "shell.execute_reply": "2025-02-14T17:20:23.824249Z",
     "shell.execute_reply.started": "2025-02-14T17:20:23.818741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_token_id = max(token_ids)\n",
    "total_tokens = len(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:20:29.687613Z",
     "iopub.status.busy": "2025-02-14T17:20:29.687308Z",
     "iopub.status.idle": "2025-02-14T17:20:29.693665Z",
     "shell.execute_reply": "2025-02-14T17:20:29.692942Z",
     "shell.execute_reply.started": "2025-02-14T17:20:29.687589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50183, 177978)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_id,total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:20:34.659775Z",
     "iopub.status.busy": "2025-02-14T17:20:34.659458Z",
     "iopub.status.idle": "2025-02-14T17:20:34.664620Z",
     "shell.execute_reply": "2025-02-14T17:20:34.663734Z",
     "shell.execute_reply.started": "2025-02-14T17:20:34.659746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.85\n",
    "train_size = int(train_ratio*len(text))\n",
    "train_data = text[:train_size]\n",
    "val_data = text[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:20:55.783315Z",
     "iopub.status.busy": "2025-02-14T17:20:55.782988Z",
     "iopub.status.idle": "2025-02-14T17:20:55.787314Z",
     "shell.execute_reply": "2025-02-14T17:20:55.786456Z",
     "shell.execute_reply.started": "2025-02-14T17:20:55.783288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataloader(data,batch_size,max_length,stride,shuffle=True,drop_last=True):\n",
    "  tokenizer = tiktoken.get_encoding('gpt2')\n",
    "  dataset = GPTDataset(data,tokenizer,max_length,stride)\n",
    "  dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle)\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:21:02.348426Z",
     "iopub.status.busy": "2025-02-14T17:21:02.348079Z",
     "iopub.status.idle": "2025-02-14T17:21:02.669116Z",
     "shell.execute_reply": "2025-02-14T17:21:02.668242Z",
     "shell.execute_reply.started": "2025-02-14T17:21:02.348397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(train_data,batch_size=2,max_length=1024,stride=256,shuffle=True,drop_last=True)\n",
    "val_dataloader = create_dataloader(val_data,batch_size=2,max_length=1024,stride=256,shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:21:11.482016Z",
     "iopub.status.busy": "2025-02-14T17:21:11.481706Z",
     "iopub.status.idle": "2025-02-14T17:21:11.520847Z",
     "shell.execute_reply": "2025-02-14T17:21:11.519950Z",
     "shell.execute_reply.started": "2025-02-14T17:21:11.481990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataloader:\n",
    "  print(x.shape,y.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:21:22.163527Z",
     "iopub.status.busy": "2025-02-14T17:21:22.163155Z",
     "iopub.status.idle": "2025-02-14T17:21:22.168200Z",
     "shell.execute_reply": "2025-02-14T17:21:22.167308Z",
     "shell.execute_reply.started": "2025-02-14T17:21:22.163498Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "for x,y in val_dataloader:\n",
    "  print(x.shape,y.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading OpenAI GPT2 weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "settings,params = gpt_download3.download_and_load_gpt2(model_size='124M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:22:42.116030Z",
     "iopub.status.busy": "2025-02-14T17:22:42.115763Z",
     "iopub.status.idle": "2025-02-14T17:22:42.120972Z",
     "shell.execute_reply": "2025-02-14T17:22:42.120143Z",
     "shell.execute_reply.started": "2025-02-14T17:22:42.115993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:39:51.064316Z",
     "iopub.status.busy": "2025-02-14T19:39:51.063988Z",
     "iopub.status.idle": "2025-02-14T19:39:51.068209Z",
     "shell.execute_reply": "2025-02-14T19:39:51.067405Z",
     "shell.execute_reply.started": "2025-02-14T19:39:51.064289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_size = settings['n_vocab']\n",
    "context_length = settings['n_ctx']\n",
    "emb_dim = settings['n_embd']\n",
    "num_heads = settings['n_head']\n",
    "num_layers = settings['n_layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:39:51.549057Z",
     "iopub.status.busy": "2025-02-14T19:39:51.548769Z",
     "iopub.status.idle": "2025-02-14T19:39:52.870789Z",
     "shell.execute_reply": "2025-02-14T19:39:52.869859Z",
     "shell.execute_reply.started": "2025-02-14T19:39:51.549032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=vocab_size,emb_dim=emb_dim,num_heads=num_heads,num_layers=num_layers,context_length=context_length,dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:22:43.572414Z",
     "iopub.status.busy": "2025-02-14T17:22:43.572088Z",
     "iopub.status.idle": "2025-02-14T17:22:43.578036Z",
     "shell.execute_reply": "2025-02-14T17:22:43.577204Z",
     "shell.execute_reply.started": "2025-02-14T17:22:43.572385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['c_fc', 'c_proj'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['blocks'][0]['mlp'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:39:56.256863Z",
     "iopub.status.busy": "2025-02-14T19:39:56.256554Z",
     "iopub.status.idle": "2025-02-14T19:39:56.466339Z",
     "shell.execute_reply": "2025-02-14T19:39:56.465424Z",
     "shell.execute_reply.started": "2025-02-14T19:39:56.256838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.token_embedding.weight = nn.Parameter(torch.tensor(params['wte']))\n",
    "model.pos_embedding.weight = nn.Parameter(torch.tensor(params['wpe']))\n",
    "\n",
    "for block in range(len(params['blocks'])):\n",
    "\n",
    "  model.trf_blocks[block].ln1.scale = nn.Parameter(torch.tensor(params['blocks'][block]['ln_1']['g']))\n",
    "  model.trf_blocks[block].ln1.shift = nn.Parameter(torch.tensor(params['blocks'][block]['ln_1']['b']))\n",
    "\n",
    "  q_w,k_w,v_w = np.split(params['blocks'][block]['attn']['c_attn']['w'],3,axis=-1)\n",
    "  model.trf_blocks[block].attn.w_q.weight = nn.Parameter(torch.tensor(q_w.T))\n",
    "  model.trf_blocks[block].attn.w_k.weight = nn.Parameter(torch.tensor(k_w.T))\n",
    "  model.trf_blocks[block].attn.w_v.weight = nn.Parameter(torch.tensor(v_w.T))\n",
    "\n",
    "  q_b,k_b,v_b = np.split(params['blocks'][block]['attn']['c_attn']['b'],3,axis=-1)\n",
    "  model.trf_blocks[block].attn.w_q.bias = nn.Parameter(torch.tensor(q_b))\n",
    "  model.trf_blocks[block].attn.w_k.bias = nn.Parameter(torch.tensor(k_b))\n",
    "  model.trf_blocks[block].attn.w_v.bias = nn.Parameter(torch.tensor(v_b))\n",
    "\n",
    "  model.trf_blocks[block].attn.out_proj.weight = nn.Parameter(torch.tensor(params['blocks'][block]['attn']['c_proj']['w'].T))\n",
    "  model.trf_blocks[block].attn.out_proj.bias = nn.Parameter(torch.tensor(params['blocks'][block]['attn']['c_proj']['b']))\n",
    "\n",
    "  model.trf_blocks[block].ln2.scale = nn.Parameter(torch.tensor(params['blocks'][block]['ln_2']['g']))\n",
    "  model.trf_blocks[block].ln2.shift = nn.Parameter(torch.tensor(params['blocks'][block]['ln_2']['b']))\n",
    "\n",
    "  model.trf_blocks[block].fcn.layers[0].weight = nn.Parameter(torch.tensor(params['blocks'][block]['mlp']['c_fc']['w'].T))\n",
    "  model.trf_blocks[block].fcn.layers[0].bias = nn.Parameter(torch.tensor(params['blocks'][block]['mlp']['c_fc']['b']))\n",
    "\n",
    "  model.trf_blocks[block].fcn.layers[2].weight = nn.Parameter(torch.tensor(params['blocks'][block]['mlp']['c_proj']['w'].T))\n",
    "  model.trf_blocks[block].fcn.layers[2].bias = nn.Parameter(torch.tensor(params['blocks'][block]['mlp']['c_proj']['b']))\n",
    "\n",
    "model.final_norm.scale = nn.Parameter(torch.tensor(params['g']))\n",
    "model.final_norm.shift = nn.Parameter(torch.tensor(params['b']))\n",
    "model.output.weight = nn.Parameter(torch.tensor(params['wte']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:25:11.577914Z",
     "iopub.status.busy": "2025-02-14T17:25:11.577627Z",
     "iopub.status.idle": "2025-02-14T17:25:11.588590Z",
     "shell.execute_reply": "2025-02-14T17:25:11.587675Z",
     "shell.execute_reply.started": "2025-02-14T17:25:11.577893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 60\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001,weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T17:25:13.784956Z",
     "iopub.status.busy": "2025-02-14T17:25:13.784613Z",
     "iopub.status.idle": "2025-02-14T17:25:13.790219Z",
     "shell.execute_reply": "2025-02-14T17:25:13.789244Z",
     "shell.execute_reply.started": "2025-02-14T17:25:13.784927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  total_losses = 0\n",
    "  for data in tqdm(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    x,y = data\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    logits = model(x)\n",
    "    loss = criterion(logits.view(-1,logits.shape[-1]),y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_losses += loss.item()\n",
    "    writer.add_scalar(\"Loss/train\", total_losses/len(train_dataloader), epoch)\n",
    "  train_losses.append(total_losses/len(train_dataloader))\n",
    "  print(f\"Epoch {epoch+1} : Training_losses : {total_losses/len(train_dataloader)}\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "      model.eval()\n",
    "      total_val_losses = 0\n",
    "      for val_data in val_dataloader:\n",
    "        x,y = val_data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1,logits.shape[-1]),y.view(-1))\n",
    "        total_val_losses += loss.item()\n",
    "        writer.add_scalar(\"Loss/val\", total_val_losses/len(val_dataloader), epoch)\n",
    "      print(f\"Epoch {epoch+1} : Validation losses :{total_val_losses/len(val_dataloader)}\")\n",
    "  val_losses.append(total_val_losses/len(val_dataloader))\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:20:21.818286Z",
     "iopub.status.busy": "2025-02-14T19:20:21.817992Z",
     "iopub.status.idle": "2025-02-14T19:20:22.905559Z",
     "shell.execute_reply": "2025-02-14T19:20:22.904720Z",
     "shell.execute_reply.started": "2025-02-14T19:20:21.818264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'LLM_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.state_dict(torch.load(\"LLM_model.pth\",weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:40:06.135735Z",
     "iopub.status.busy": "2025-02-14T19:40:06.135457Z",
     "iopub.status.idle": "2025-02-14T19:40:06.140634Z",
     "shell.execute_reply": "2025-02-14T19:40:06.139625Z",
     "shell.execute_reply.started": "2025-02-14T19:40:06.135714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(model,input_text,max_new_tokens,context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        model_input = input_text[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(model_input)\n",
    "        last_token = logits[:,-1,:]\n",
    "        probs = torch.softmax(last_token,dim = -1)\n",
    "        predicted_token = torch.argmax(probs,dim = -1,keepdim = True)\n",
    "        # print(input_text.shape,predicted_token.shape)\n",
    "        input_text = torch.cat([input_text,predicted_token],dim = 1)\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:40:29.275675Z",
     "iopub.status.busy": "2025-02-14T19:40:29.275396Z",
     "iopub.status.idle": "2025-02-14T19:40:29.279924Z",
     "shell.execute_reply": "2025-02-14T19:40:29.278979Z",
     "shell.execute_reply.started": "2025-02-14T19:40:29.275656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_text = 'the nerves of brain'\n",
    "input_text_tokenized = tokenizer.encode(input_text)\n",
    "input_text_encoded = torch.tensor(input_text_tokenized).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:40:52.159598Z",
     "iopub.status.busy": "2025-02-14T19:40:52.159287Z",
     "iopub.status.idle": "2025-02-14T19:40:55.768368Z",
     "shell.execute_reply": "2025-02-14T19:40:55.767432Z",
     "shell.execute_reply.started": "2025-02-14T19:40:52.159571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the nerves of brain cells, and the brain's ability to process information.  The researchers found that the brain's ability to process information is also affected by the amount of information it receives.  \"The brain\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "context_size = 1024\n",
    "prediction = predict(model,input_text_encoded,40,context_size)\n",
    "prediction = prediction.squeeze(0)\n",
    "decoded_text = tokenizer.decode(prediction.tolist())\n",
    "print(decoded_text.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6659096,
     "sourceId": 10739061,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6659278,
     "sourceId": 10739294,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6659285,
     "sourceId": 10739308,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
